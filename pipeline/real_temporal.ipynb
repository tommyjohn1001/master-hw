{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='NPE'\n",
    "dataset='ml-100k'\n",
    "\n",
    "config_dict = {\n",
    "    'eval_args': {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": {\"RS\": [0.8, 0.1, 0.1]},\n",
    "        \"group_by\": None\n",
    "    },\n",
    "    'train_neg_sample_args': None\n",
    "}\n",
    "\n",
    "config = Config(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    config_dict=config_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.time_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(config)\n",
    "# train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "# model_type = config[\"MODEL_TYPE\"]\n",
    "# built_datasets = dataset.build()\n",
    "# train_dataset, valid_dataset, test_dataset = built_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.inter_feat.sort_values(by=dataset.time_field, ascending=True, inplace=True)\n",
    "cutoff_conv = 0.351652\n",
    "\n",
    "group_by = 'user_id'\n",
    "grouped_inter_feat_index = dataset._grouped_index(dataset.inter_feat[group_by])\n",
    "\n",
    "next_index = [[]]*3\n",
    "for grouped_index in grouped_inter_feat_index:\n",
    "    df_each_user = dataset.inter_feat.loc[grouped_index].sort_values(dataset.time_field)\n",
    "    \n",
    "    df_before = df_each_user[df_each_user[dataset.time_field] < cutoff_conv]\n",
    "    df_after = df_each_user[df_each_user[dataset.time_field] >= cutoff_conv]\n",
    "\n",
    "    if len(df_before) == 0:\n",
    "        continue\n",
    "\n",
    "    if len(df_before) >= 1:\n",
    "        next_index[0].extend(df_before.iloc[:-1].index)\n",
    "    if len(df_before) >= 2:\n",
    "        next_index[1].extend(df_before.iloc[-1].index)\n",
    "\n",
    "    if len(df_after) > 0:\n",
    "        next_index[2].extend(df_after.iloc[0].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_each_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.inter_feat.loc[grouped_index].sort_values(dataset.time_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.inter_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.float_like_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = \"timestamp\"\n",
    "\n",
    "assert field in dataset.fields(), f\"Dataset not existed field '{field}'\"\n",
    "\n",
    "for feat in dataset.field2feats(field):\n",
    "    break\n",
    "\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.field2feats(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.inter_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = 'user_id'\n",
    "# grouped_inter_feat_index = dataset._grouped_index(dataset.inter_feat[group_by].numpy())\n",
    "\n",
    "dataset.inter_feat[group_by].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement time cutoff Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from recbole.data.dataloader import *\n",
    "from recbole.sampler import KGSampler, Sampler, RepeatableSampler\n",
    "from recbole.utils import ModelType, ensure_dir, get_local_time, set_color\n",
    "from recbole.utils.argument_list import dataset_arguments\n",
    "from recbole.data.dataset import Dataset\n",
    "from recbole.utils import (\n",
    "    FeatureType,\n",
    "    set_color,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: HoangLe [Jun-09]: How to replace config[\"MODEL_TYPE\"] to TimeCutoffDataset\n",
    "\n",
    "MODELTYPE_CUTOFF = 7\n",
    "\n",
    "class TimeCutoffDataset(Dataset):\n",
    "    def __init__(self, config):\n",
    "        self.timestamp_max, self.timestamp_min = 0., 0.\n",
    "        self.cutoff, self.cutoff_conv = 0., 0.\n",
    "\n",
    "        super().__init__(config)\n",
    "\n",
    "    def _normalize(self):\n",
    "        # Extract max-min of field self.time_field\n",
    "        # feat_timestamp = self.field2feats(self.time_field)[0]\n",
    "        # assert feat_timestamp and self.time_field in feat_timestamp, f\"Feat not exist field '{self.time_field}'\"\n",
    "\n",
    "        # self.timestamp_max = np.max(feat_timestamp[self.time_field])\n",
    "        # self.timestamp_min = np.min(feat_timestamp[self.time_field])\n",
    "\n",
    "        self.timestamp_max = np.max(self.inter_feat[self.time_field])\n",
    "        self.timestamp_min = np.min(self.inter_feat[self.time_field])\n",
    "\n",
    "        return super()._normalize()\n",
    "\n",
    "    def _fill_nan(self):\n",
    "        \"\"\"Missing value imputation.\n",
    "\n",
    "        For fields with type :obj:`~recbole.utils.enum_type.FeatureType.TOKEN`, missing value will be filled by\n",
    "        ``[PAD]``, which indexed as 0.\n",
    "\n",
    "        For fields with type :obj:`~recbole.utils.enum_type.FeatureType.FLOAT`, missing value will be filled by\n",
    "        the average of original data.\n",
    "\n",
    "        Note:\n",
    "            This is similar to the recbole's original implementation. The difference is the change in inplace operation to suit the pandas 3.0\n",
    "        \"\"\"\n",
    "        self.logger.debug(set_color(\"Filling nan\", \"green\"))\n",
    "\n",
    "        for feat_name in self.feat_name_list:\n",
    "            feat = getattr(self, feat_name)\n",
    "            for field in feat:\n",
    "                ftype = self.field2type[field]\n",
    "                if ftype == FeatureType.TOKEN:\n",
    "                    feat[field] = feat[field].fillna(value=0)\n",
    "                elif ftype == FeatureType.FLOAT:\n",
    "                    feat[field] = feat[field].fillna(value=feat[field].mean())\n",
    "                else:\n",
    "                    dtype = np.int64 if ftype == FeatureType.TOKEN_SEQ else np.float64\n",
    "                    feat[field] = feat[field].apply(\n",
    "                        lambda x: (\n",
    "                            np.array([], dtype=dtype) if isinstance(x, float) else x\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    def build(self):\n",
    "        self._change_feat_format()\n",
    "\n",
    "        if self.benchmark_filename_list is not None:\n",
    "            super().build()\n",
    "\n",
    "        # ordering\n",
    "        ordering_args = self.config[\"eval_args\"][\"order\"]\n",
    "        if ordering_args == \"TO\":\n",
    "            self.sort(by=self.time_field)\n",
    "        else:\n",
    "            raise AssertionError(\"The ordering_method must be 'TO.\")\n",
    "\n",
    "        # splitting & grouping\n",
    "        split_args = self.config[\"eval_args\"][\"split\"]\n",
    "        if split_args is None:\n",
    "            raise ValueError(\"The split_args in eval_args should not be None.\")\n",
    "        if not isinstance(split_args, dict):\n",
    "            raise ValueError(f\"The split_args [{split_args}] should be a dict.\")\n",
    "\n",
    "        split_mode = list(split_args.keys())[0]\n",
    "        assert len(split_args.keys()) == 1\n",
    "        if split_mode != \"CO\":\n",
    "            raise NotImplementedError(\"The split_mode must be 'CO'.\")\n",
    "        elif split_mode == \"CO\":\n",
    "            cutoff = split_args[\"RS\"]\n",
    "            # NOTE: HoangLe [Jun-05]: cutoff may come with different types: string, int\n",
    "\n",
    "            group_by = self.config[\"eval_args\"][\"group_by\"]\n",
    "            datasets = self.split_by_cuttoff(cutoff=cutoff, group_by=group_by)\n",
    "    \n",
    "        \n",
    "        return datasets\n",
    "\n",
    "    def split_by_cuttoff(self, cutoff: str|int, group_by: str) -> list[Dataset]:\n",
    "        \"\"\"Split the interations by cutoff date\n",
    "\n",
    "        Args:\n",
    "            cutoff (str | int): cutoff date in Unix timestamp format\n",
    "            group_by (str): field to group by, usually the user_id\n",
    "\n",
    "        Returns:\n",
    "            list[Dataset]: list of training/validation/testing dataset, whose interaction features has been split.\n",
    "\n",
    "        Notes:\n",
    "            cutoff may be different types: string of Unix timestamp (e.g. '1717923174'), integer of Unix timestamp (e.g. 1717923174)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.debug(f\"split by cutoff date = '{cutoff}', group_by=[{group_by}]\")\n",
    "\n",
    "        # Convert cutoff to suitable format and apply 0-1 normalization with max/min timestamp\n",
    "        if isinstance(cutoff, str):\n",
    "            cutoff_conv = float(cutoff)\n",
    "        else:\n",
    "            cutoff_conv = float(cutoff)\n",
    "\n",
    "        def norm_timestamp(timestamp: float):\n",
    "            mx, mn = self.timestamp_max, self.timestamp_min\n",
    "            if mx == mn:\n",
    "                self.logger.warning(\n",
    "                    f\"All the same value in [{field}] from [{feat}_feat].\"\n",
    "                )\n",
    "                arr = 1.0\n",
    "            else:\n",
    "                arr = (timestamp - mn) / (mx - mn)\n",
    "            return arr\n",
    "\n",
    "        cutoff_conv = norm_timestamp(cutoff_conv)\n",
    "            \n",
    "\n",
    "        grouped_inter_feat_index = self._grouped_index(self.inter_feat[group_by].to_numpy())\n",
    "\n",
    "        next_index = [[]]*3     # 'next_index' contains the indices for training/validation/testing dataset\n",
    "        for grouped_index in grouped_inter_feat_index:\n",
    "            df_each_user = dataset.inter_feat.loc[grouped_index].sort_values(dataset.time_field)\n",
    "            \n",
    "            df_before = df_each_user[df_each_user[dataset.time_field] < cutoff_conv]\n",
    "            df_after = df_each_user[df_each_user[dataset.time_field] >= cutoff_conv]\n",
    "\n",
    "            if len(df_before) == 0:\n",
    "                continue\n",
    "\n",
    "            if len(df_before) >= 1:\n",
    "                next_index[0].extend(df_before.iloc[:-1].index)\n",
    "            if len(df_before) >= 2:\n",
    "                next_index[1].extend(df_before.iloc[-1].index)\n",
    "\n",
    "            if len(df_after) > 0:\n",
    "                next_index[2].extend(df_after.iloc[0].index)\n",
    "            \n",
    "\n",
    "        self._drop_unused_col()\n",
    "        next_df = [self.inter_feat[index] for index in next_index]\n",
    "        next_ds = [self.copy(_) for _ in next_df]\n",
    "        return next_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='NPE'\n",
    "dataset='ml-100k'\n",
    "\n",
    "config_dict = {\n",
    "    'eval_args': {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": {\"cutoff\": '12731432'},\n",
    "        \"group_by\": 'user_id'\n",
    "    },\n",
    "    'train_neg_sample_args': None\n",
    "}\n",
    "\n",
    "config = Config(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    config_dict=config_dict\n",
    ")\n",
    "\n",
    "# Set model_type as type of TimeCutoffDataset\n",
    "config['MODEL_TYPE'] = MODELTYPE_CUTOFF\n",
    "dataset = TimeCutoffDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.915478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.224244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.316897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.628862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>876</td>\n",
       "      <td>174</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.293651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>709</td>\n",
       "      <td>248</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.273185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>38</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>59</td>\n",
       "      <td>444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.413451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>305</td>\n",
       "      <td>507</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.282022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "0            1        1    0.50   0.351593\n",
       "1            2        2    0.50   0.915478\n",
       "2            3        3    0.00   0.224244\n",
       "3            4        4    0.25   0.316897\n",
       "4            5        5    0.00   0.628862\n",
       "...        ...      ...     ...        ...\n",
       "99995      876      174    0.50   0.293651\n",
       "99996      709      248    1.00   0.273185\n",
       "99997       38     1005    0.00   0.003830\n",
       "99998       59      444    0.25   0.413451\n",
       "99999      305      507    0.50   0.282022\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.inter_feat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
